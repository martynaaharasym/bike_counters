{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ef4fbb-26b7-439a-b088-8669c00c8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from jours_feries_france import JoursFeries\n",
    "\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a90d03-05c1-4410-992d-ced4a7f6bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                counter_id              counter_name    site_id  \\\n",
      "48321  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48324  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48327  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48330  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48333  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "\n",
      "                  site_name  bike_count                date  \\\n",
      "48321  28 boulevard Diderot         0.0 2020-09-01 02:00:00   \n",
      "48324  28 boulevard Diderot         1.0 2020-09-01 03:00:00   \n",
      "48327  28 boulevard Diderot         0.0 2020-09-01 04:00:00   \n",
      "48330  28 boulevard Diderot         4.0 2020-09-01 15:00:00   \n",
      "48333  28 boulevard Diderot         9.0 2020-09-01 18:00:00   \n",
      "\n",
      "      counter_installation_date         coordinates counter_technical_id  \\\n",
      "48321                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48324                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48327                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48330                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48333                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "\n",
      "        latitude  longitude  log_bike_count  \n",
      "48321  48.846028   2.375429        0.000000  \n",
      "48324  48.846028   2.375429        0.693147  \n",
      "48327  48.846028   2.375429        0.000000  \n",
      "48330  48.846028   2.375429        1.609438  \n",
      "48333  48.846028   2.375429        2.302585  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 496827 entries, 48321 to 929187\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 496827 non-null  category      \n",
      " 1   counter_name               496827 non-null  category      \n",
      " 2   site_id                    496827 non-null  int64         \n",
      " 3   site_name                  496827 non-null  category      \n",
      " 4   bike_count                 496827 non-null  float64       \n",
      " 5   date                       496827 non-null  datetime64[us]\n",
      " 6   counter_installation_date  496827 non-null  datetime64[us]\n",
      " 7   coordinates                496827 non-null  category      \n",
      " 8   counter_technical_id       496827 non-null  category      \n",
      " 9   latitude                   496827 non-null  float64       \n",
      " 10  longitude                  496827 non-null  float64       \n",
      " 11  log_bike_count             496827 non-null  float64       \n",
      "dtypes: category(5), datetime64[us](2), float64(4), int64(1)\n",
      "memory usage: 32.7 MB\n",
      "None\n",
      "DatetimeIndex(['2020-01-01', '2020-04-13', '2020-05-01', '2020-05-08',\n",
      "               '2020-05-21'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "data = pd.read_parquet(Path(\"data\") / \"train.parquet\")\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "data.to_csv('data.csv')\n",
    "    \n",
    "# Define holidays for 2020 and 2021\n",
    "holidays_2020_2021 = (\n",
    "    list(JoursFeries.for_year(2020).values()) +\n",
    "    list(JoursFeries.for_year(2021).values())\n",
    ")\n",
    "holidays_2020_2021 = pd.to_datetime(holidays_2020_2021)\n",
    "print(holidays_2020_2021[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d55c83-0b1b-4c50-8146-efcccb36435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _encode_dates(X):\n",
    "#    \"\"\"\n",
    "#    Encode date information from the 'date' column.\n",
    "#    Adds year, month, day, weekday, hour, holiday, and weekend indicators.\n",
    "#    \"\"\"\n",
    "\n",
    "#    lockdown_periods = [\n",
    "#        (\"2020-03-17\", \"2020-05-11\"),\n",
    "#        (\"2020-10-30\", \"2020-12-14\"),\n",
    "#        (\"2021-04-03\", \"2021-06-30\"),\n",
    "#    ]\n",
    "    \n",
    "#    lockdown_ranges = [\n",
    "#        (pd.to_datetime(start), pd.to_datetime(end)) for start, end in lockdown_periods\n",
    "#    ]\n",
    "    \n",
    "#    X = X.copy()\n",
    "#    X[\"year\"] = X[\"date\"].dt.year\n",
    "#    X[\"month\"] = X[\"date\"].dt.month\n",
    "#    X[\"day\"] = X[\"date\"].dt.day\n",
    "#    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "#    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "#    X['holiday'] = X['date'].isin(holidays_2020_2021).astype(int)\n",
    "#    X['weekend'] = (X['date'].dt.dayofweek > 4).astype(int)\n",
    "#    X[\"lockdown\"] = X[\"date\"].apply(\n",
    "#        lambda d: any(start <= d <= end for start, end in lockdown_ranges)\n",
    "#    ).astype(int)\n",
    "    \n",
    "#    return X.drop(columns=[\"date\"])\n",
    "\n",
    "# Check the date column\n",
    "# print(data[\"date\"].head())\n",
    "\n",
    "# Apply encoding function\n",
    "# encoded_dates = _encode_dates(data[[\"date\"]])\n",
    "# print(encoded_dates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77fdfa58-2a45-4ad2-a4e8-d0a74302d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    \"\"\"\n",
    "    Encode date information from the 'date' column.\n",
    "    Adds year, month, day, weekday, hour, holiday, weekend indicators, lockdown, is_sun, and cyclical hour features.\n",
    "    \"\"\"\n",
    "    # Define lockdown periods\n",
    "    lockdown_periods = [\n",
    "        (\"2020-03-17\", \"2020-05-11\"),\n",
    "        (\"2020-10-30\", \"2020-12-14\"),\n",
    "        (\"2021-04-03\", \"2021-06-30\"),\n",
    "    ]\n",
    "    lockdown_ranges = [\n",
    "        (pd.to_datetime(start), pd.to_datetime(end)) for start, end in lockdown_periods\n",
    "    ]\n",
    "\n",
    "    # Define daylight data\n",
    "    daylight_data = {\n",
    "        'month': [\n",
    "            'January', 'February', 'March', 'April', 'May', 'June',\n",
    "            'July', 'August', 'September', 'October', 'November', 'December'\n",
    "        ],\n",
    "        'sunrise': [\n",
    "            '08:37', '07:57', '07:01', '06:56', '06:06', '05:44',\n",
    "            '06:02', '06:42', '07:26', '08:10', '07:58', '08:35'\n",
    "        ],\n",
    "        'sunset': [\n",
    "            '17:22', '18:11', '18:57', '20:44', '21:27', '21:58',\n",
    "            '21:51', '21:07', '20:04', '19:02', '17:11', '16:56'\n",
    "        ]\n",
    "    }\n",
    "    daylight_df = pd.DataFrame(daylight_data)\n",
    "\n",
    "    # Convert sunrise and sunset times to timedelta\n",
    "    daylight_df['sunrise'] = pd.to_timedelta(daylight_df['sunrise'] + ':00')\n",
    "    daylight_df['sunset'] = pd.to_timedelta(daylight_df['sunset'] + ':00')\n",
    "\n",
    "    # Copy input DataFrame\n",
    "    X = X.copy()\n",
    "\n",
    "    # Add basic date components\n",
    "    X[\"year\"] = X[\"date\"].dt.year\n",
    "    X[\"month\"] = X[\"date\"].dt.month_name()\n",
    "    X[\"day\"] = X[\"date\"].dt.day\n",
    "    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "    X[\"holiday\"] = X[\"date\"].isin(holidays_2020_2021).astype(int)\n",
    "    X[\"weekend\"] = (X[\"date\"].dt.dayofweek > 4).astype(int)\n",
    "\n",
    "    # Add lockdown information\n",
    "    X[\"lockdown\"] = X[\"date\"].apply(\n",
    "        lambda d: any(start <= d <= end for start, end in lockdown_ranges)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Map sunrise and sunset times to the DataFrame\n",
    "    X = X.merge(daylight_df, on='month', how='left')\n",
    "\n",
    "    # Calculate time of day as timedelta since midnight\n",
    "    X['time_of_day'] = (\n",
    "        X['date'].dt.hour * 3600 +\n",
    "        X['date'].dt.minute * 60 +\n",
    "        X['date'].dt.second\n",
    "    ).apply(pd.to_timedelta, unit='s')\n",
    "\n",
    "    # Add is_sun column\n",
    "    X['is_sun'] = (\n",
    "        (X['time_of_day'] >= X['sunrise']) &\n",
    "        (X['time_of_day'] <= X['sunset'])\n",
    "    ).astype(int)\n",
    "\n",
    "    # Add cyclical hour features\n",
    "    X['sin_hour'] = np.sin(2 * np.pi * X['hour'] / 24)\n",
    "    X['cos_hour'] = np.cos(2 * np.pi * X['hour'] / 24)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    X = X.drop(columns=[\"date\", \"sunrise\", \"sunset\", \"time_of_day\", \"month\", \"hour\"])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adca3360-f147-4967-91ef-d835a16d7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FunctionTransformer and preprocessor\n",
    "date_encoder = FunctionTransformer(_encode_dates, validate=False)\n",
    "date_cols = _encode_dates(data[[\"date\"]]).columns.tolist()\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a162fc1-e262-45fa-8d03-b32082c6ac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   ff       t   u    vv     n    pres  ht_neige  rr1\n",
      "0  2021-01-01 00:00:00  1.8  272.75  96   990  10.0   99680      0.00  0.0\n",
      "1  2021-01-01 03:00:00  1.7  271.25  98   210  25.0   99790      0.00  0.0\n",
      "2  2021-01-01 06:00:00  2.6  271.95  98  3660  90.0   99820      0.00  0.0\n",
      "3  2021-01-01 09:00:00  1.7  272.45  97  3500  50.0   99970      0.01  0.0\n",
      "4  2021-01-01 12:00:00  1.0  276.95  82  8000  90.0  100000     -0.01  0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3322 entries, 0 to 3321\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   date      3322 non-null   object \n",
      " 1   ff        3322 non-null   float64\n",
      " 2   t         3322 non-null   float64\n",
      " 3   u         3322 non-null   int64  \n",
      " 4   vv        3322 non-null   int64  \n",
      " 5   n         3166 non-null   float64\n",
      " 6   pres      3322 non-null   int64  \n",
      " 7   ht_neige  3273 non-null   float64\n",
      " 8   rr1       3313 non-null   float64\n",
      "dtypes: float64(5), int64(3), object(1)\n",
      "memory usage: 233.7+ KB\n",
      "None\n",
      "            counter_id              counter_name    site_id  \\\n",
      "0  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "1  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "2  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "3  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "4  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "\n",
      "              site_name  bike_count                date  \\\n",
      "0  28 boulevard Diderot         0.0 2020-09-01 02:00:00   \n",
      "1  28 boulevard Diderot         1.0 2020-09-01 03:00:00   \n",
      "2  28 boulevard Diderot         0.0 2020-09-01 04:00:00   \n",
      "3  28 boulevard Diderot         4.0 2020-09-01 15:00:00   \n",
      "4  28 boulevard Diderot         9.0 2020-09-01 18:00:00   \n",
      "\n",
      "  counter_installation_date         coordinates counter_technical_id  \\\n",
      "0                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "1                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "2                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "3                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "4                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "\n",
      "    latitude  longitude  log_bike_count        ff       t          u  \\\n",
      "0  48.846028   2.375429        0.000000  1.266667  284.55  85.666667   \n",
      "1  48.846028   2.375429        0.693147  1.100000  283.95  88.000000   \n",
      "2  48.846028   2.375429        0.000000  1.333333  284.05  89.000000   \n",
      "3  48.846028   2.375429        1.609438  4.000000  293.65  41.000000   \n",
      "4  48.846028   2.375429        2.302585  3.000000  292.15  47.000000   \n",
      "\n",
      "             vv          n           pres  ht_neige  rr1  \n",
      "0  26666.666667   0.000000  100920.000000       0.0  0.0  \n",
      "1  25000.000000   0.000000  100900.000000       0.0  0.0  \n",
      "2  25000.000000   3.333333  100903.333333       0.0  0.0  \n",
      "3  30000.000000  60.000000  100690.000000       0.0  0.0  \n",
      "4  30000.000000  90.000000  100700.000000       0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "important_columns = [\"date\", \"pres\", \"ff\", \"t\", \"u\", \"vv\", \"n\", \"ht_neige\", \"rr1\"]\n",
    "\n",
    "# Load weather data\n",
    "weather_data = pd.read_csv('./external_data/external_data.csv', usecols=important_columns)\n",
    "print(weather_data.head())\n",
    "print(weather_data.info())\n",
    "\n",
    "# Process weather data\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "weather_data = weather_data.dropna(axis=1, how='all')\n",
    "weather_data.set_index('date', inplace=True)\n",
    "weather_data = weather_data[~weather_data.index.duplicated(keep='first')]\n",
    "weather_data_interpolated = weather_data.resample('h').interpolate(method='linear')\n",
    "\n",
    "# Merge with main dataset\n",
    "merged_data = data.merge(weather_data_interpolated, on='date', how='left')\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbba5a8-0106-4cb8-98da-5e7c63291317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'xgbregressor__learning_rate': 0.2, 'xgbregressor__max_depth': 7, 'xgbregressor__n_estimators': 300}\n",
      "Test RMSE: 0.534080834088994\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = merged_data[[\"counter_name\", \"date\", \"longitude\", \"latitude\", \"ff\", \"t\", \"u\", \"vv\", \"n\", \"pres\", \"ht_neige\", \"rr1\"]]\n",
    "y = merged_data['log_bike_count']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model and pipeline\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "pipe = make_pipeline(date_encoder, preprocessor, model)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'xgbregressor__n_estimators': [100, 200, 300],\n",
    "    'xgbregressor__max_depth': [3, 5, 7],\n",
    "    'xgbregressor__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=4\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab78ab8a-b317-4d23-b8e7-eda7fca74fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess test set\n",
    "df_test = pd.read_parquet(\"./data/final_test.parquet\")\n",
    "df_test_merged = df_test.merge(weather_data_interpolated, on='date', how='left')\n",
    "df_test_merged = df_test_merged.assign(**_encode_dates(df_test_merged[[\"date\"]]))\n",
    "\n",
    "# Prepare features for prediction\n",
    "X_test_final = df_test_merged[[\"counter_name\", \"date\", \"longitude\", \"latitude\", \"ff\", \"t\", \"u\", \"vv\", \"n\", \"pres\", \"ht_neige\", \"rr1\"]]\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=np.arange(y_pred.shape[0]),\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
