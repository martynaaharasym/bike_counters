{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ef4fbb-26b7-439a-b088-8669c00c8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from jours_feries_france import JoursFeries\n",
    "\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a90d03-05c1-4410-992d-ced4a7f6bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                counter_id              counter_name    site_id  \\\n",
      "48321  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48324  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48327  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48330  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "48333  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "\n",
      "                  site_name  bike_count                date  \\\n",
      "48321  28 boulevard Diderot         0.0 2020-09-01 02:00:00   \n",
      "48324  28 boulevard Diderot         1.0 2020-09-01 03:00:00   \n",
      "48327  28 boulevard Diderot         0.0 2020-09-01 04:00:00   \n",
      "48330  28 boulevard Diderot         4.0 2020-09-01 15:00:00   \n",
      "48333  28 boulevard Diderot         9.0 2020-09-01 18:00:00   \n",
      "\n",
      "      counter_installation_date         coordinates counter_technical_id  \\\n",
      "48321                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48324                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48327                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48330                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "48333                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "\n",
      "        latitude  longitude  log_bike_count  \n",
      "48321  48.846028   2.375429        0.000000  \n",
      "48324  48.846028   2.375429        0.693147  \n",
      "48327  48.846028   2.375429        0.000000  \n",
      "48330  48.846028   2.375429        1.609438  \n",
      "48333  48.846028   2.375429        2.302585  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 496827 entries, 48321 to 929187\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 496827 non-null  category      \n",
      " 1   counter_name               496827 non-null  category      \n",
      " 2   site_id                    496827 non-null  int64         \n",
      " 3   site_name                  496827 non-null  category      \n",
      " 4   bike_count                 496827 non-null  float64       \n",
      " 5   date                       496827 non-null  datetime64[us]\n",
      " 6   counter_installation_date  496827 non-null  datetime64[us]\n",
      " 7   coordinates                496827 non-null  category      \n",
      " 8   counter_technical_id       496827 non-null  category      \n",
      " 9   latitude                   496827 non-null  float64       \n",
      " 10  longitude                  496827 non-null  float64       \n",
      " 11  log_bike_count             496827 non-null  float64       \n",
      "dtypes: category(5), datetime64[us](2), float64(4), int64(1)\n",
      "memory usage: 32.7 MB\n",
      "None\n",
      "DatetimeIndex(['2020-01-01', '2020-04-13', '2020-05-01', '2020-05-08',\n",
      "               '2020-05-21'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "data = pd.read_parquet(Path(\"data\") / \"train.parquet\")\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "# Define holidays for 2020 and 2021\n",
    "holidays_2020_2021 = (\n",
    "    list(JoursFeries.for_year(2020).values()) +\n",
    "    list(JoursFeries.for_year(2021).values())\n",
    ")\n",
    "holidays_2020_2021 = pd.to_datetime(holidays_2020_2021)\n",
    "print(holidays_2020_2021[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d55c83-0b1b-4c50-8146-efcccb36435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48321   2020-09-01 02:00:00\n",
      "48324   2020-09-01 03:00:00\n",
      "48327   2020-09-01 04:00:00\n",
      "48330   2020-09-01 15:00:00\n",
      "48333   2020-09-01 18:00:00\n",
      "Name: date, dtype: datetime64[us]\n",
      "       year  month  day  weekday  hour  holiday  weekend\n",
      "48321  2020      9    1        1     2        0        0\n",
      "48324  2020      9    1        1     3        0        0\n",
      "48327  2020      9    1        1     4        0        0\n",
      "48330  2020      9    1        1    15        0        0\n",
      "48333  2020      9    1        1    18        0        0\n"
     ]
    }
   ],
   "source": [
    "def _encode_dates(X):\n",
    "    \"\"\"\n",
    "    Encode date information from the 'date' column.\n",
    "    Adds year, month, day, weekday, hour, holiday, and weekend indicators.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    X[\"year\"] = X[\"date\"].dt.year\n",
    "    X[\"month\"] = X[\"date\"].dt.month\n",
    "    X[\"day\"] = X[\"date\"].dt.day\n",
    "    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "    X['holiday'] = X['date'].isin(holidays_2020_2021).astype(int)\n",
    "    X['weekend'] = (X['date'].dt.dayofweek > 4).astype(int)\n",
    "    return X.drop(columns=[\"date\"])\n",
    "\n",
    "# Check the date column\n",
    "print(data[\"date\"].head())\n",
    "\n",
    "# Apply encoding function\n",
    "encoded_dates = _encode_dates(data[[\"date\"]])\n",
    "print(encoded_dates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adca3360-f147-4967-91ef-d835a16d7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FunctionTransformer and preprocessor\n",
    "date_encoder = FunctionTransformer(_encode_dates, validate=False)\n",
    "date_cols = _encode_dates(data[[\"date\"]]).columns.tolist()\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\", \"site_name\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a162fc1-e262-45fa-8d03-b32082c6ac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   ff       t   u    vv     n    hbas    pres  ht_neige  \\\n",
      "0  2021-01-01 00:00:00  1.8  272.75  96   990  10.0   800.0   99680      0.00   \n",
      "1  2021-01-01 03:00:00  1.7  271.25  98   210  25.0  1750.0   99790      0.00   \n",
      "2  2021-01-01 06:00:00  2.6  271.95  98  3660  90.0   450.0   99820      0.00   \n",
      "3  2021-01-01 09:00:00  1.7  272.45  97  3500  50.0  1750.0   99970      0.01   \n",
      "4  2021-01-01 12:00:00  1.0  276.95  82  8000  90.0   450.0  100000     -0.01   \n",
      "\n",
      "   rr1  \n",
      "0  0.0  \n",
      "1  0.0  \n",
      "2  0.0  \n",
      "3  0.0  \n",
      "4  0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3322 entries, 0 to 3321\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   date      3322 non-null   object \n",
      " 1   ff        3322 non-null   float64\n",
      " 2   t         3322 non-null   float64\n",
      " 3   u         3322 non-null   int64  \n",
      " 4   vv        3322 non-null   int64  \n",
      " 5   n         3166 non-null   float64\n",
      " 6   hbas      2869 non-null   float64\n",
      " 7   pres      3322 non-null   int64  \n",
      " 8   ht_neige  3273 non-null   float64\n",
      " 9   rr1       3313 non-null   float64\n",
      "dtypes: float64(6), int64(3), object(1)\n",
      "memory usage: 259.7+ KB\n",
      "None\n",
      "            counter_id              counter_name    site_id  \\\n",
      "0  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "1  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "2  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "3  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "4  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
      "\n",
      "              site_name  bike_count                date  \\\n",
      "0  28 boulevard Diderot         0.0 2020-09-01 02:00:00   \n",
      "1  28 boulevard Diderot         1.0 2020-09-01 03:00:00   \n",
      "2  28 boulevard Diderot         0.0 2020-09-01 04:00:00   \n",
      "3  28 boulevard Diderot         4.0 2020-09-01 15:00:00   \n",
      "4  28 boulevard Diderot         9.0 2020-09-01 18:00:00   \n",
      "\n",
      "  counter_installation_date         coordinates counter_technical_id  \\\n",
      "0                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "1                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "2                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "3                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "4                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "\n",
      "    latitude  ...  log_bike_count        ff       t          u            vv  \\\n",
      "0  48.846028  ...        0.000000  1.266667  284.55  85.666667  26666.666667   \n",
      "1  48.846028  ...        0.693147  1.100000  283.95  88.000000  25000.000000   \n",
      "2  48.846028  ...        0.000000  1.333333  284.05  89.000000  25000.000000   \n",
      "3  48.846028  ...        1.609438  4.000000  293.65  41.000000  30000.000000   \n",
      "4  48.846028  ...        2.302585  3.000000  292.15  47.000000  30000.000000   \n",
      "\n",
      "           n    hbas           pres  ht_neige  rr1  \n",
      "0   0.000000     NaN  100920.000000       0.0  0.0  \n",
      "1   0.000000     NaN  100900.000000       0.0  0.0  \n",
      "2   3.333333     NaN  100903.333333       0.0  0.0  \n",
      "3  60.000000  1750.0  100690.000000       0.0  0.0  \n",
      "4  90.000000  1750.0  100700.000000       0.0  0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "important_columns = [\"date\", \"pres\", \"ff\", \"t\", \"u\", \"vv\", \"n\", \"hbas\", \"ht_neige\", \"rr1\"]\n",
    "\n",
    "# Load weather data\n",
    "weather_data = pd.read_csv('./external_data/external_data.csv', usecols=important_columns)\n",
    "print(weather_data.head())\n",
    "print(weather_data.info())\n",
    "\n",
    "# Process weather data\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "weather_data = weather_data.dropna(axis=1, how='all')\n",
    "weather_data.set_index('date', inplace=True)\n",
    "weather_data = weather_data[~weather_data.index.duplicated(keep='first')]\n",
    "weather_data_interpolated = weather_data.resample('h').interpolate(method='linear')\n",
    "\n",
    "# Merge with main dataset\n",
    "merged_data = data.merge(weather_data_interpolated, on='date', how='left')\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbba5a8-0106-4cb8-98da-5e7c63291317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = merged_data[[\"counter_name\", \"site_name\", \"date\", \"longitude\", \"latitude\", \"ff\", \"t\", \"u\", \"vv\", \"n\", \"hbas\", \"pres\", \"ht_neige\", \"rr1\"]]\n",
    "y = merged_data['log_bike_count']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model and pipeline\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "pipe = make_pipeline(date_encoder, preprocessor, model)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'xgbregressor__n_estimators': [100, 200, 300],\n",
    "    'xgbregressor__max_depth': [3, 5, 7],\n",
    "    'xgbregressor__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78ab8a-b317-4d23-b8e7-eda7fca74fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess test set\n",
    "df_test = pd.read_parquet(\"./data/final_test.parquet\")\n",
    "df_test_merged = df_test.merge(weather_data_interpolated, on='date', how='left')\n",
    "\n",
    "# Prepare features for prediction\n",
    "X_test_final = df_test_merged[[\"counter_name\", \"site_name\", \"date\", \"longitude\", \"latitude\", \"ff\", \"t\", \"u\", \"vv\", \"n\", \"hbas\", \"pres\", \"ht_neige\", \"rr1\"]]\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=np.arange(y_pred.shape[0]),\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e90b1-d8e0-4f4a-9d17-f20ba570a6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
